{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/roykallaye/TyDiP-for-Colab/blob/main/TyDiP_regressor_colab_notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "F28XJOqb9o8B",
        "outputId": "24c27d0c-fbc9-4d9a-fd3c-074df6119ee2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement torch==1.9.0+cu111 (from versions: 1.11.0, 1.11.0+cpu, 1.11.0+cu102, 1.11.0+cu113, 1.11.0+cu115, 1.11.0+rocm4.3.1, 1.11.0+rocm4.5.2, 1.12.0, 1.12.0+cpu, 1.12.0+cu102, 1.12.0+cu113, 1.12.0+cu116, 1.12.0+rocm5.0, 1.12.0+rocm5.1.1, 1.12.1, 1.12.1+cpu, 1.12.1+cu102, 1.12.1+cu113, 1.12.1+cu116, 1.12.1+rocm5.0, 1.12.1+rocm5.1.1, 1.13.0, 1.13.0+cpu, 1.13.0+cu116, 1.13.0+cu117, 1.13.0+cu117.with.pypi.cudnn, 1.13.0+rocm5.1.1, 1.13.0+rocm5.2, 1.13.1, 1.13.1+cpu, 1.13.1+cu116, 1.13.1+cu117, 1.13.1+cu117.with.pypi.cudnn, 1.13.1+rocm5.1.1, 1.13.1+rocm5.2, 2.0.0, 2.0.0+cpu, 2.0.0+cpu.cxx11.abi, 2.0.0+cu117, 2.0.0+cu117.with.pypi.cudnn, 2.0.0+cu118, 2.0.0+rocm5.3, 2.0.0+rocm5.4.2, 2.0.1, 2.0.1+cpu, 2.0.1+cpu.cxx11.abi, 2.0.1+cu117, 2.0.1+cu117.with.pypi.cudnn, 2.0.1+cu118, 2.0.1+rocm5.3, 2.0.1+rocm5.4.2, 2.1.0, 2.1.0+cpu, 2.1.0+cpu.cxx11.abi, 2.1.0+cu118, 2.1.0+cu121, 2.1.0+cu121.with.pypi.cudnn, 2.1.0+rocm5.5, 2.1.0+rocm5.6, 2.1.1, 2.1.1+cpu, 2.1.1+cpu.cxx11.abi, 2.1.1+cu118, 2.1.1+cu121, 2.1.1+cu121.with.pypi.cudnn, 2.1.1+rocm5.5, 2.1.1+rocm5.6, 2.1.2, 2.1.2+cpu, 2.1.2+cpu.cxx11.abi, 2.1.2+cu118, 2.1.2+cu121, 2.1.2+cu121.with.pypi.cudnn, 2.1.2+rocm5.5, 2.1.2+rocm5.6, 2.2.0, 2.2.0+cpu, 2.2.0+cpu.cxx11.abi, 2.2.0+cu118, 2.2.0+cu121, 2.2.0+rocm5.6, 2.2.0+rocm5.7, 2.2.1, 2.2.1+cpu, 2.2.1+cpu.cxx11.abi, 2.2.1+cu118, 2.2.1+cu121, 2.2.1+rocm5.6, 2.2.1+rocm5.7, 2.2.2, 2.2.2+cpu, 2.2.2+cpu.cxx11.abi, 2.2.2+cu118, 2.2.2+cu121, 2.2.2+rocm5.6, 2.2.2+rocm5.7, 2.3.0, 2.3.0+cpu, 2.3.0+cpu.cxx11.abi, 2.3.0+cu118, 2.3.0+cu121, 2.3.0+rocm5.7, 2.3.0+rocm6.0, 2.3.1, 2.3.1+cpu, 2.3.1+cpu.cxx11.abi, 2.3.1+cu118, 2.3.1+cu121, 2.3.1+rocm5.7, 2.3.1+rocm6.0, 2.4.0, 2.4.1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for torch==1.9.0+cu111\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: pytorch-lightning==1.5.0 in /usr/local/lib/python3.10/dist-packages (1.5.0)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.5.0) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.6 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.5.0) (2.4.1+cu121)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.5.0) (1.0.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.5.0) (4.66.5)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.5.0) (6.0.2)\n",
            "Requirement already satisfied: fsspec!=2021.06.0,>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.0) (2024.6.1)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.5.0) (2.17.0)\n",
            "Requirement already satisfied: torchmetrics>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.5.0) (1.4.2)\n",
            "Requirement already satisfied: pyDeprecate==0.3.1 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.5.0) (0.3.1)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.5.0) (24.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning==1.5.0) (4.12.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.0) (3.10.5)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.0) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.0) (1.64.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.0) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.0) (3.20.3)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.0) (71.0.4)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.0) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.0) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard>=2.2.0->pytorch-lightning==1.5.0) (3.0.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->pytorch-lightning==1.5.0) (3.16.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->pytorch-lightning==1.5.0) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->pytorch-lightning==1.5.0) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.6->pytorch-lightning==1.5.0) (3.1.4)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from torchmetrics>=0.4.1->pytorch-lightning==1.5.0) (0.11.7)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.0) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.0) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.0) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.0) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.0) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.0) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.2.0->pytorch-lightning==1.5.0) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.6->pytorch-lightning==1.5.0) (1.3.0)\n",
            "Requirement already satisfied: idna>=2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]!=2021.06.0,>=2021.05.0->pytorch-lightning==1.5.0) (3.10)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.1.4)\n",
            "Requirement already satisfied: numpy<2,>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Requirement already satisfied: polyglot in /usr/local/lib/python3.10/dist-packages (16.7.4)\n",
            "Requirement already satisfied: pyicu in /usr/local/lib/python3.10/dist-packages (2.13.1)\n",
            "Requirement already satisfied: pycld2 in /usr/local/lib/python3.10/dist-packages (0.41)\n",
            "Requirement already satisfied: morfessor in /usr/local/lib/python3.10/dist-packages (2.0.6)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets) (3.16.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.26.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.1.4)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.24.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.22.0->datasets) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy\n",
        "!pip install torch==1.9.0+cu111 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install pytorch-lightning==1.5.0\n",
        "!pip install scikit-learn\n",
        "!pip install transformers\n",
        "!pip install pandas\n",
        "!pip install polyglot\n",
        "!pip install pyicu\n",
        "!pip install pycld2\n",
        "!pip install morfessor\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZkV2m4K8fpr",
        "outputId": "0c4b4b79-7b4d-482a-bd9f-e1577a212fd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/training_type/ddp.py:68: DeprecationWarning: `TorchScript` support for functional optimizers is deprecated and will be removed in a future PyTorch release. Consider using the `torch.compile` optimizer instead.\n",
            "  from torch.distributed.optim import DistributedOptimizer\n"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "from typing import List, Dict\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "import os\n",
        "\n",
        "os.chdir('/content/drive/MyDrive/Colab Notebooks/TyDiP')\n",
        "\n",
        "import sys\n",
        "import numpy as np\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import seed_everything\n",
        "import sklearn.metrics\n",
        "import sklearn.model_selection\n",
        "import torch\n",
        "import torch.optim\n",
        "import torch.utils.data\n",
        "import transformers\n",
        "import pandas as pd\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IUmKO6JA-1pR"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    from polyglot.text import Text\n",
        "except:\n",
        "    print(\"polyglot not installed. Cannot use --strategy_words\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wi52YPzW-o72"
      },
      "outputs": [],
      "source": [
        "class MyDataModule(pl.LightningDataModule):\n",
        "    def __init__(self, train_file, test_file, binary, tokenizer, max_length, batch_size, strategy_words_replacement_negate=False, strategy_words=None, random_masking_ratio=None):\n",
        "        super().__init__()\n",
        "        self.train_file = train_file\n",
        "        self.test_file = test_file\n",
        "        self.binary = binary\n",
        "        self.max_length = max_length\n",
        "        self.batch_size = batch_size\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "        if strategy_words:\n",
        "            self.strategy_words = pd.read_csv(strategy_words)\n",
        "            self.strategy_words = set(list(self.strategy_words.values[:, 1:].reshape(-1)))\n",
        "        else:\n",
        "            self.strategy_words = None\n",
        "        self.strategy_words_replacement_negate = strategy_words_replacement_negate\n",
        "        self.random_masking_ratio = random_masking_ratio\n",
        "\n",
        "    @staticmethod\n",
        "    def read_file(file_name, text_only=False):\n",
        "        if file_name.split(\".\")[-1] == \"csv\":\n",
        "            df = pd.read_csv(file_name)\n",
        "            data = [(a, b) for a, b in zip(list(df['sentence']), df['score'])]\n",
        "            if text_only:\n",
        "                data = [t[0] for t in data]\n",
        "        else:\n",
        "            data = open(file_name).read().strip().split('\\n')\n",
        "        return data\n",
        "\n",
        "    def setup(self, stage=None):\n",
        "        if self.train_file:\n",
        "            self.train_data = MyDataModule.read_file(self.train_file)\n",
        "            self.train_data, self.val_data = sklearn.model_selection.train_test_split(self.train_data, shuffle=False, test_size=0.2)\n",
        "        if self.test_file:\n",
        "            self.test_data = MyDataModule.read_file(self.test_file)\n",
        "\n",
        "    def prepare_dataloader(self, mode):\n",
        "        if mode == \"train\":\n",
        "            data = self.train_data\n",
        "        elif mode == \"val\":\n",
        "            data = self.val_data\n",
        "        else:\n",
        "            data = self.test_data\n",
        "\n",
        "        # tokenized = self.tokenizer([t[0] for t in data], padding=\"max_length\", truncation=True, max_length=self.max_length, return_tensors=\"pt\")\n",
        "        tokenized = MyDataModule.tokenize([t[0] for t in data], self.tokenizer, self.max_length, self.strategy_words_replacement_negate, self.strategy_words, self.random_masking_ratio)\n",
        "        if self.binary:\n",
        "            labels = torch.tensor([t[1] > 0 for t in data], dtype=int)\n",
        "        else:\n",
        "            labels = torch.tensor([t[1] for t in data])\n",
        "\n",
        "        if mode == \"train\":\n",
        "            weights = torch.zeros_like(labels)\n",
        "            weights[labels == 0] = labels.shape[0] - labels.sum()\n",
        "            weights[labels == 1] = labels.sum()\n",
        "            return torch.utils.data.DataLoader(torch.utils.data.TensorDataset(tokenized['input_ids'], tokenized['attention_mask'], labels), batch_size=self.batch_size, sampler=torch.utils.data.WeightedRandomSampler(1 / weights, len(weights), replacement=True))\n",
        "        else:\n",
        "            return torch.utils.data.DataLoader(torch.utils.data.TensorDataset(tokenized['input_ids'], tokenized['attention_mask'], labels), batch_size=self.batch_size)\n",
        "\n",
        "    @staticmethod\n",
        "    def tokenize(data: List[str], tokenizer, max_length, strategy_words_replacement_negate, strategy_words, random_masking_ratio):\n",
        "        if strategy_words is not None or random_masking_ratio is not None:\n",
        "            tokenized_data = []\n",
        "            for sentence in data:\n",
        "                words = Text(sentence).words\n",
        "                words = [t.lower() for t in words]\n",
        "                if strategy_words:\n",
        "                    words = [t if ((t in strategy_words) != strategy_words_replacement_negate) else tokenizer.mask_token for t in words]\n",
        "                elif random_masking_ratio:\n",
        "                    words = [t if random.random() <= random_masking_ratio else tokenizer.mask_token for t in words]\n",
        "                tokenized_data.append(' '.join(words))\n",
        "            out = tokenizer(tokenized_data, padding=\"max_length\", truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
        "            # out['attention_mask'] = torch.tensor(out['input_ids'] != tokenizer.pad_token_id, dtype=int)\n",
        "            return out\n",
        "        else:\n",
        "            return tokenizer(data, padding=\"max_length\", truncation=True, max_length=max_length, return_tensors=\"pt\")\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return self.prepare_dataloader(\"train\")\n",
        "        # return torch.utils.data.DataLoader(MyDataModule.CustomDataset1(self.tokenizer, self.train_data, self.max_length), batch_size=self.batch_size)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return self.prepare_dataloader(\"test\")\n",
        "        # return torch.utils.data.DataLoader(MyDataModule.CustomDataset1(self.tokenizer, self.test_data, self.max_length), batch_size=self.batch_size)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return self.prepare_dataloader(\"val\")\n",
        "        # return torch.utils.data.DataLoader(MyDataModule.CustomDataset1(self.tokenizer, self.val_data, self.max_length), batch_size=self.batch_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzC5Wf3u-_M_"
      },
      "source": [
        "# New section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mzLwc9t8rR-W"
      },
      "outputs": [],
      "source": [
        "class RegressionModel(pl.LightningModule):\n",
        "    def __init__(self, pretrained_model, binary, learning_rate, num_warmup_steps, tokenizer):\n",
        "        super(RegressionModel, self).__init__()\n",
        "        self.save_hyperparameters()\n",
        "        self.pretrained_model = pretrained_model\n",
        "        self.binary = binary\n",
        "        self.learning_rate = learning_rate\n",
        "        self.num_warmup_steps = num_warmup_steps\n",
        "        self.tokenizer = tokenizer\n",
        "        self.model = transformers.AutoModelForSequenceClassification.from_pretrained(self.pretrained_model, num_labels=2 if self.binary else 1)\n",
        "\n",
        "    def forward(self, **kwargs):\n",
        "        return self.model(**kwargs)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        outputs = self.forward(input_ids=batch[0], attention_mask=batch[1], labels=batch[2])\n",
        "        loss = outputs['loss']\n",
        "        ret = {\"loss\": loss}\n",
        "        if self.binary:\n",
        "            acc = torch.tensor(batch[2] == torch.argmax(outputs['logits']), dtype=float).mean().item()\n",
        "            ret[\"acc\"] = acc\n",
        "        else:\n",
        "            rmse = (torch.mean((batch[2] - outputs['logits'])**2)**0.5).item()\n",
        "            ret[\"rmse\"] = rmse\n",
        "\n",
        "        return {\"loss\": loss, \"log\": ret}\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.learning_rate)\n",
        "        scheduler = transformers.get_linear_schedule_with_warmup(optimizer, self.num_warmup_steps, len(self.trainer.datamodule.train_dataloader()) // self.trainer.accumulate_grad_batches)\n",
        "        return [optimizer], [{\"scheduler\": scheduler}]\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        return self.validation_step(batch, batch_idx, mode=\"test\")\n",
        "\n",
        "    def validation_step(self, batch, batch_idx, mode=\"val\"):\n",
        "        outputs = self.forward(input_ids=batch[0], attention_mask=batch[1], labels=batch[2])\n",
        "        loss = outputs['loss']\n",
        "        self.log(\"{}_loss\".format(mode), loss, prog_bar=True)\n",
        "\n",
        "        ret = {\"loss\": loss}\n",
        "        if self.binary:\n",
        "            preds = torch.argmax(outputs['logits'], axis=1).tolist()\n",
        "            gold = batch[2].tolist()\n",
        "            ret[\"preds\"] = preds\n",
        "            ret[\"gold\"] = gold\n",
        "            # f1 = sklearn.metrics.f1_score(gold, preds)\n",
        "            # acc = sklearn.metrics.accuracy_score(gold, preds)\n",
        "            # ret[\"acc\"] = acc\n",
        "            # ret[\"f1\"] = f1\n",
        "            # self.log(\"{}_acc\".format(mode), acc, prog_bar=True)\n",
        "            # self.log(\"{}_f1\".format(mode), f1, prog_bar=True)\n",
        "        else:\n",
        "            preds = outputs['logits'].tolist()\n",
        "            gold = batch[2].tolist()\n",
        "            ret['preds'] = preds\n",
        "            ret['gold'] = gold\n",
        "            # rmse = (torch.mean((batch[2] - outputs['logits'])**2)**0.5).item()\n",
        "            # self.log(\"{}_rmse\".format(mode), rmse, prog_bar=True)\n",
        "            # ret[\"rmse\"] = rmse\n",
        "\n",
        "        return {\"loss\": loss, \"log\": ret}\n",
        "\n",
        "    def validation_epoch_end(self, outputs, mode=\"val\"):\n",
        "        gold = []\n",
        "        preds = []\n",
        "        for batch in outputs:\n",
        "            gold.extend(batch['log']['gold'])\n",
        "            preds.extend(batch['log']['preds'])\n",
        "        if self.binary:\n",
        "            f1 = sklearn.metrics.f1_score(gold, preds)\n",
        "            acc = sklearn.metrics.accuracy_score(gold, preds)\n",
        "            self.log(\"{}_acc\".format(mode), acc, prog_bar=True)\n",
        "            self.log(\"{}_f1\".format(mode), f1, prog_bar=True)\n",
        "        else:\n",
        "            rmse = (torch.mean((torch.tensor(gold) - torch.tensor(preds))**2)**0.5).item()\n",
        "            self.log(\"{}_rmse\".format(mode), rmse, prog_bar=True)\n",
        "\n",
        "    def test_epoch_end(self, outputs):\n",
        "        return self.validation_epoch_end(outputs, mode=\"test\")\n",
        "\n",
        "    def predict_step(self, batch, batch_idx):\n",
        "        preds = self.forward(input_ids=batch[0], attention_mask=batch[1])\n",
        "        if self.binary:\n",
        "            ret = preds['logits'].tolist()\n",
        "        else:\n",
        "            ret = preds['logits'].view(-1).tolist()\n",
        "        return ret\n",
        "\n",
        "    @staticmethod\n",
        "    def add_model_specific_args(parent_parser):\n",
        "        parser = parent_parser.add_argument_group(\"RegressionModel\")\n",
        "        parser.add_argument('--pretrained_model', type=str)\n",
        "        parser.add_argument('--learning_rate', type=float, default=\"5e-6\")\n",
        "        parser.add_argument('--num_warmup_steps', type=float, default=\"0\")\n",
        "        return parent_parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3GtJ9Fwy_V9F"
      },
      "outputs": [],
      "source": [
        "def main():\n",
        "    # Argument Parser\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--train\", action=\"store_true\")\n",
        "    parser.add_argument(\"--test\", action=\"store_true\")\n",
        "    parser.add_argument(\"--load_model\", type=str)\n",
        "    parser.add_argument(\"--train_file\", type=str)\n",
        "    parser.add_argument(\"--test_file\", type=str)\n",
        "    parser.add_argument(\"--binary\", action=\"store_true\")\n",
        "    parser.add_argument(\"--seed\", type=int, default=42)\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=64)\n",
        "    parser.add_argument(\"--max_length\", type=int, default=128)\n",
        "    parser.add_argument(\"--model_save_location\", type=str)\n",
        "    parser.add_argument(\"--preds_save_location\", type=str)\n",
        "    parser.add_argument(\"--preds_save_logits\", action=\"store_true\")\n",
        "    parser.add_argument(\"--strategy_words\", type=str)\n",
        "    parser.add_argument(\"--strategy_words_replacement_negate\", action=\"store_true\")\n",
        "    parser.add_argument(\"--random_masking_ratio\", type=float)\n",
        "\n",
        "    # Add model-specific arguments and trainer-specific arguments\n",
        "    parser = RegressionModel.add_model_specific_args(parser)\n",
        "    parser = pl.Trainer.add_argparse_args(parser)\n",
        "\n",
        "    # Use parse_known_args() to ignore any unrecognized arguments (such as those passed by Jupyter/Colab)\n",
        "    args, unknown = parser.parse_known_args()\n",
        "\n",
        "    # Print recognized arguments and unknown arguments for debugging purposes\n",
        "    print(\"Recognized arguments:\", args)\n",
        "    print(\"Unknown arguments:\", unknown)\n",
        "\n",
        "    # Seed everything\n",
        "    seed_everything(seed=args.seed)\n",
        "\n",
        "    # Load model or initialize new model\n",
        "    if args.load_model:\n",
        "      # Load the tokenizer using the model name\n",
        "      tokenizer = transformers.AutoTokenizer.from_pretrained(args.load_model)\n",
        "\n",
        "      # Instantiate the RegressionModel with the necessary parameters\n",
        "      model = RegressionModel(\n",
        "          pretrained_model=args.load_model,\n",
        "          binary=args.binary,\n",
        "          learning_rate=args.learning_rate,\n",
        "          num_warmup_steps=args.num_warmup_steps,\n",
        "          tokenizer=tokenizer\n",
        "      )\n",
        "\n",
        "    else:\n",
        "        # Set the pretrained model to 'xlm-roberta-large' as specified in the README\n",
        "        pretrained_model = \"Genius1237/xlm-roberta-large-tydip\"\n",
        "        tokenizer = transformers.AutoTokenizer.from_pretrained(pretrained_model)\n",
        "        model = RegressionModel(\n",
        "            pretrained_model=pretrained_model,\n",
        "            binary=True,\n",
        "            learning_rate=args.learning_rate,\n",
        "            num_warmup_steps=args.num_warmup_steps,\n",
        "            tokenizer=tokenizer\n",
        "        )\n",
        "\n",
        "    # Initialize Trainer\n",
        "    trainer = pl.Trainer.from_argparse_args(args)\n",
        "\n",
        "    # Load dataset\n",
        "    dataset = MyDataModule(\n",
        "        train_file=args.train_file,\n",
        "        test_file=args.test_file,\n",
        "        binary=model.binary,\n",
        "        max_length=args.max_length,\n",
        "        batch_size=args.batch_size,\n",
        "        tokenizer=tokenizer,\n",
        "        strategy_words_replacement_negate=args.strategy_words_replacement_negate,\n",
        "        strategy_words=args.strategy_words,\n",
        "        random_masking_ratio=args.random_masking_ratio\n",
        "    )\n",
        "    dataset.setup()\n",
        "\n",
        "    # Train model if --train argument is provided\n",
        "    if args.train:\n",
        "        trainer.fit(model, dataset)\n",
        "\n",
        "    # Test model if --test argument is provided\n",
        "    if args.test:\n",
        "        trainer.test(model, dataset.test_dataloader())\n",
        "\n",
        "    # Save predictions if --preds_save_location argument is provided\n",
        "    if args.preds_save_location:\n",
        "        data = MyDataModule.read_file(args.test_file, True)\n",
        "        strategy_words = None\n",
        "        if args.strategy_words:\n",
        "            strategy_words = pd.read_csv(args.strategy_words)\n",
        "            strategy_words = set(list(args.strategy_words.values[:, 1:].reshape(-1)))\n",
        "        tokenized = MyDataModule.tokenize(data, tokenizer, args.max_length, args.strategy_words_replacement_negate, strategy_words, args.random_masking_ratio)\n",
        "        input_data = torch.utils.data.DataLoader(\n",
        "            torch.utils.data.TensorDataset(tokenized['input_ids'], tokenized['attention_mask']),\n",
        "            batch_size=args.batch_size\n",
        "        )\n",
        "        preds = trainer.predict(model, input_data, return_predictions=True)\n",
        "        preds = [t for y in preds for t in y]\n",
        "        preds = torch.tensor(preds)\n",
        "        if model.binary:\n",
        "            if args.preds_save_logits:\n",
        "                preds = torch.softmax(preds, axis=1)[:, 1].tolist()\n",
        "            else:\n",
        "                preds = preds.argmax(axis=1).tolist()\n",
        "        else:\n",
        "            preds = preds.view(-1).tolist()\n",
        "        preds = [str(t) for t in preds]\n",
        "\n",
        "        with open(args.preds_save_location, 'w') as f:\n",
        "            f.write('\\n'.join(preds) + '\\n')\n",
        "\n",
        "    # Save model if --model_save_location argument is provided\n",
        "    if args.model_save_location:\n",
        "        trainer.save_checkpoint(args.model_save_location, weights_only=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "SKIP 3 CELLS"
      ],
      "metadata": {
        "id": "-aHCWCZeiD_z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ec0Bymd5eVG"
      },
      "outputs": [],
      "source": [
        "sys.argv = [\n",
        "    'politeness_regressor.py',  # Your script name, adjust if necessary\n",
        "    #'--train',                   # Indicates that you want to train the model\n",
        "    '--train_file', 'data/binary/en_train_binary.csv',  # Path to your training file\n",
        "    '--test_file', 'data/binary/en_test_binary.csv',    # Path to your testing file\n",
        "    '--model_save_location', 'model.pt',  # Path to save the trained model\n",
        "    '--gpus', '1',               # Use 1 GPU for training\n",
        "    '--batch_size', '4',         # Set your desired batch size\n",
        "    '--max_epochs', '5',         # Number of training epochs\n",
        "    '--learning_rate', '5e-6',   # Set learning rate\n",
        "    '--checkpoint_callback', 'False',  # Disable checkpointing\n",
        "    '--logger', 'False',         # Disable logging\n",
        "    '--binary',                  # Set this if your model is binary classification\n",
        "]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 549
        },
        "collapsed": true,
        "id": "lFoRdcuiCM3v",
        "outputId": "645bf401-c4a4-4411-e0aa-6d70cc58d402"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:pytorch_lightning.utilities.seed:Global seed set to 42\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recognized arguments: Namespace(train=False, test=False, load_model=None, train_file='data/binary/en_train_binary.csv', test_file='data/binary/en_test_binary.csv', binary=True, seed=42, batch_size=4, max_length=128, model_save_location='model.pt', preds_save_location=None, preds_save_logits=False, strategy_words=None, strategy_words_replacement_negate=False, random_masking_ratio=None, pretrained_model=None, learning_rate=5e-06, num_warmup_steps=0.0, logger=False, checkpoint_callback=False, enable_checkpointing=True, default_root_dir=None, gradient_clip_val=None, gradient_clip_algorithm=None, process_position=0, num_nodes=1, num_processes=1, devices=None, gpus=1, auto_select_gpus=False, tpu_cores=None, ipus=None, log_gpu_memory=None, progress_bar_refresh_rate=None, enable_progress_bar=True, overfit_batches=0.0, track_grad_norm=-1, check_val_every_n_epoch=1, fast_dev_run=False, accumulate_grad_batches=None, max_epochs=5, min_epochs=None, max_steps=-1, min_steps=None, max_time=None, limit_train_batches=1.0, limit_val_batches=1.0, limit_test_batches=1.0, limit_predict_batches=1.0, val_check_interval=1.0, flush_logs_every_n_steps=None, log_every_n_steps=50, accelerator=None, strategy=None, sync_batchnorm=False, precision=32, enable_model_summary=True, weights_summary='top', weights_save_path=None, num_sanity_val_steps=2, resume_from_checkpoint=None, profiler=None, benchmark=False, deterministic=False, reload_dataloaders_every_n_epochs=0, reload_dataloaders_every_epoch=False, auto_lr_find=False, replace_sampler_ddp=True, detect_anomaly=False, auto_scale_batch_size=False, prepare_data_per_node=None, plugins=None, amp_backend='native', amp_level=None, move_metrics_to_cpu=False, multiple_trainloader_mode='max_size_cycle', stochastic_weight_avg=False, terminate_on_nan=None)\n",
            "Unknown arguments: []\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/callback_connector.py:147: LightningDeprecationWarning: Setting `Trainer(checkpoint_callback=False)` is deprecated in v1.5 and will be removed in v1.7. Please consider using `Trainer(enable_checkpointing=False)`.\n",
            "  rank_zero_deprecation(\n",
            "INFO:pytorch_lightning.utilities.distributed:GPU available: True, used: True\n",
            "INFO:pytorch_lightning.utilities.distributed:TPU available: False, using: 0 TPU cores\n",
            "INFO:pytorch_lightning.utilities.distributed:IPU available: False, using: 0 IPUs\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'NoneType' object has no attribute 'state_dict'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-972361fa1b80>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-22-f0fad9e5afdb>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[0;31m# Save model if --model_save_location argument is provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_save_location\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_save_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36msave_checkpoint\u001b[0;34m(self, filepath, weights_only)\u001b[0m\n\u001b[1;32m   1899\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1900\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_PATH\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1901\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_connector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1902\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1903\u001b[0m     \"\"\"\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py\u001b[0m in \u001b[0;36msave_checkpoint\u001b[0;34m(self, filepath, weights_only)\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0mweights_only\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msaving\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0mweights\u001b[0m \u001b[0monly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m         \"\"\"\n\u001b[0;32m--> 471\u001b[0;31m         \u001b[0m_checkpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights_only\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py\u001b[0m in \u001b[0;36mdump_checkpoint\u001b[0;34m(self, weights_only)\u001b[0m\n\u001b[1;32m    371\u001b[0m             \u001b[0;34m\"global_step\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m             \u001b[0;34m\"pytorch-lightning_version\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m             \u001b[0;34m\"state_dict\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lightning_module_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    374\u001b[0m         }\n\u001b[1;32m    375\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_fault_tolerant_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/trainer/connectors/checkpoint_connector.py\u001b[0m in \u001b[0;36m_get_lightning_module_state_dict\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m         \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_type_plugin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmetric\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pytorch_lightning/plugins/training_type/training_type_plugin.py\u001b[0m in \u001b[0;36mlightning_module_state_dict\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    282\u001b[0m         \u001b[0;34m\"\"\"Returns model state.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    283\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlightning_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 284\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    285\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheckpoint\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mDict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_PATH\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'state_dict'"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CnZwnClCiqYc",
        "outputId": "3a8e9281-312d-4421-b096-59bff78e9cbd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'\\x80\\x02}q\\x00(X\\x05\\x00\\x00\\x00epochq\\x01K\\x05X\\x0b\\x00\\x00\\x00global_stepq\\x02M\\x8b\\x07X\\x19\\x00\\x00\\x00pytorch-lightning_versionq\\x03X\\x05\\x00\\x00\\x001.5.0q\\x04X\\n\\x00\\x00\\x00state_dictq\\x05ccollections\\nOrderedDict\\nq\\x06)Rq\\x07(X/\\x00\\x00\\x00model.roberta.embeddings.word_embeddings.weightq\\x08ctorch._utils\\n_rebuild_tensor_v2\\nq\\t((X\\x07\\x00\\x00\\x00storageq\\nctorch\\nFloatStorage\\nq\\x0bX\\x01\\x00\\x00\\x000q\\x0cX\\x03\\x00\\x00\\x00cpuq\\rJ\\x00HB\\x0ftq\\x0eQK\\x00J\\x92\\xd0\\x03\\x00M\\x00\\x04\\x86q\\x0fM\\x00\\x04K\\x01\\x86q\\x10\\x89h\\x06)Rq\\x11tq\\x12Rq\\x13X3\\x00\\x00\\x00model.roberta.embeddings.position_embeddings.weightq\\x14h\\t((h\\nh\\x0bX\\x01\\x00\\x00\\x001q\\x15h\\rJ\\x00\\x08\\x08\\x00tq\\x16QK\\x00M\\x02\\x02M\\x00\\x04\\x86q\\x17M\\x00\\x04K\\x01\\x86q\\x18\\x89h\\x06)Rq\\x19tq\\x1aRq\\x1bX5\\x00\\x00\\x00model.roberta.embeddings.token_type_embeddings.weightq\\x1ch'\n"
          ]
        }
      ],
      "source": [
        "pkl_file_path = 'archive/data.pkl'\n",
        "\n",
        "with open(pkl_file_path, 'rb') as f:\n",
        "    file_content = f.read()\n",
        "    print(file_content[:500])  # Print the first 500 characters to inspect\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "RESUME RUNNING CELLS"
      ],
      "metadata": {
        "id": "4FU-DU2YiIsk"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275,
          "referenced_widgets": [
            "c106e359cc1e4a66bb6ccec7964d12bc",
            "b1e43741163e42c3944737f71af07e8e",
            "d73b4c52587d4222b4d8813404712200",
            "0294bc3a9d8f48628a44b9e86128e9a7",
            "b6f563bd8e2c45d9913542f95ec33d40",
            "77aa134124dc4f04b0d2e4606b932322",
            "2149bff204494d76b209cab30fbaa3e1",
            "42586d06b43f40708abd7d95cee1ca24",
            "9dffa8e8a4c14b31b84ca902abb40cb5",
            "fce82f7968a14a5e94c657ba6632853d",
            "f3f4b85d1e744c5da1dd5ff238357a6d",
            "f580bac555e842ae94ffd29e62709e98",
            "3e2c8459510842c491d47e4a0d8eb552",
            "e87ed39fc2994f019a873bf6b5def6d8",
            "d9a67ec1766444cb99a33a9648b69772",
            "ff38210dae914397a37a86a2b4461f98",
            "6859ae51c650492181c06b90b5c40660",
            "c855fdfb3d8d4a768f049b84dc631b21",
            "4741b65283f947f78334ad76ac4caf35",
            "79f983f21c34453585e1ef80d3b92496",
            "8ae6d7ad932e40d79ea93503bee24dc9",
            "d44b67aaf7664f329505f194ee40325d"
          ]
        },
        "id": "ta4ZAJj4khl-",
        "outputId": "d3e63239-97dd-4912-aa9a-26eaf25d574d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/cloud_io.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(f, map_location=map_location)\n",
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/core/lightning.py:2058: DeprecationWarning: `torch.distributed._sharded_tensor` will be deprecated, use `torch.distributed._shard.sharded_tensor` instead\n",
            "  from torch.distributed._sharded_tensor import pre_load_state_dict_hook, state_dict_hook\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/827 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c106e359cc1e4a66bb6ccec7964d12bc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.24G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f580bac555e842ae94ffd29e62709e98"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from pytorch_lightning import LightningModule\n",
        "from transformers import XLMRobertaForSequenceClassification\n",
        "\n",
        "# Load the model using your LightningModule class\n",
        "model = RegressionModel.load_from_checkpoint('model.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5K5RGAyoovr_"
      },
      "outputs": [],
      "source": [
        "# Load the test dataset\n",
        "test_file_path = 'data/binary/fr_test_binary.csv'\n",
        "#test_data = pd.read_csv(test_file_path)\n",
        "\n",
        "test_data = pd.read_csv(test_file_path, encoding='ISO-8859-1')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qA3ICPlrIyj"
      },
      "outputs": [],
      "source": [
        "# from datasets import load_dataset\n",
        "\n",
        "# # Load the test dataset for the desired language (e.g., English)\n",
        "# test_dataset = load_dataset(\"path.to.your.TyDiP.py\", \"en\", split=\"test\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wt_hXPAdo8lP",
        "outputId": "985e8d72-81dc-4d34-9a36-af7b8bca0f5f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import XLMRobertaTokenizer\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = XLMRobertaTokenizer.from_pretrained('xlm-roberta-base')\n",
        "\n",
        "# Tokenize the dataset\n",
        "def tokenize_function(examples):\n",
        "    return tokenizer(examples, padding=\"max_length\", truncation=True)  # Use padding and truncation for fixed-size inputs\n",
        "\n",
        "# Apply tokenization\n",
        "tokenized_test_dataset = test_data['sentence'].map(tokenize_function)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "bbvyVI4JtVq1",
        "outputId": "4fb8c53a-2ccf-401f-e03c-42f3357fa4ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pytorch_lightning/utilities/cloud_io.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  return torch.load(f, map_location=map_location)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RegressionModel(\n",
              "  (model): XLMRobertaForSequenceClassification(\n",
              "    (roberta): XLMRobertaModel(\n",
              "      (embeddings): XLMRobertaEmbeddings(\n",
              "        (word_embeddings): Embedding(250002, 1024, padding_idx=1)\n",
              "        (position_embeddings): Embedding(514, 1024, padding_idx=1)\n",
              "        (token_type_embeddings): Embedding(1, 1024)\n",
              "        (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "        (dropout): Dropout(p=0.1, inplace=False)\n",
              "      )\n",
              "      (encoder): XLMRobertaEncoder(\n",
              "        (layer): ModuleList(\n",
              "          (0-23): 24 x XLMRobertaLayer(\n",
              "            (attention): XLMRobertaAttention(\n",
              "              (self): XLMRobertaSelfAttention(\n",
              "                (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "              (output): XLMRobertaSelfOutput(\n",
              "                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "                (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "                (dropout): Dropout(p=0.1, inplace=False)\n",
              "              )\n",
              "            )\n",
              "            (intermediate): XLMRobertaIntermediate(\n",
              "              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "              (intermediate_act_fn): GELUActivation()\n",
              "            )\n",
              "            (output): XLMRobertaOutput(\n",
              "              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (classifier): XLMRobertaClassificationHead(\n",
              "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "      (out_proj): Linear(in_features=1024, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "# Create DataLoader (batch_size can be increased, but 1 is fine for now)\n",
        "test_dataloader = DataLoader(tokenized_test_dataset, batch_size=1)\n",
        "\n",
        "# Load your model\n",
        "model = RegressionModel.load_from_checkpoint('model.pt')\n",
        "model.eval()  # Set the model to evaluation mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YiJN8Dbek_8y"
      },
      "outputs": [],
      "source": [
        "# Prepare to store predictions and true labels\n",
        "predictions = []\n",
        "true_labels = test_data['score'].tolist()  # Access 'score' column from the original test_data DataFrame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjXuMKVNvJh9",
        "outputId": "009043fb-8d4b-459b-a9da-1963f4dcb640"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of true_labels: 250\n",
            "Length of predictions: 250\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Step 1: Make Predictions\n",
        "with torch.no_grad():  # Disable gradient calculation\n",
        "    for batch in test_dataloader:\n",
        "        # Move input tensors to the same device as the model (if necessary)\n",
        "        batch = {key: torch.tensor(val).unsqueeze(0).to(model.device) for key, val in batch.items()}\n",
        "\n",
        "        # Get model outputs\n",
        "        outputs = model(**batch)\n",
        "\n",
        "        # Get logits (for sentence, usually first token's logits)\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Get the predicted class label for the entire sentence\n",
        "        predicted_label = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "\n",
        "        # Store the predictions\n",
        "        predictions.extend(predicted_label)\n",
        "\n",
        "# Check the lengths of true_labels and predictions\n",
        "print(f\"Length of true_labels: {len(true_labels)}\")\n",
        "print(f\"Length of predictions: {len(predictions)}\")\n",
        "\n",
        "if len(true_labels) != len(predictions):\n",
        "    print(\"WARNING: Lengths of true_labels and predictions do not match!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZEMrU1doyFgr"
      },
      "outputs": [],
      "source": [
        "# Binarize true labels based on a threshold\n",
        "threshold = 0.5\n",
        "true_labels_binary = [1 if score > threshold else 0 for score in true_labels]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tvqGR_o4qnoY",
        "outputId": "322da923-1eba-4925-ea99-65cc5bd5e4b4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8840\n",
            "F1 Score: 0.8830\n"
          ]
        }
      ],
      "source": [
        "# Step 2: Evaluate Performance\n",
        "if len(true_labels_binary) == len(predictions):\n",
        "    # Calculate accuracy and F1 score\n",
        "    accuracy = accuracy_score(true_labels_binary, predictions)\n",
        "    f1 = f1_score(true_labels_binary, predictions, average='weighted')  # Adjust as needed\n",
        "    print(f\"Accuracy: {accuracy:.4f}\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "else:\n",
        "    print(\"WARNING: Lengths of true_labels and predictions do not match!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkKkJsKG4KsL",
        "outputId": "744a324b-3c8f-49a1-bd56-d6e608e21850"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              Sentence  True Score  \\\n",
            "0    Allons bon, tu me dis que tu n'acceptes pas qu...   -0.476638   \n",
            "1    Bonjour Maloq  C'tait pas la peine de me fil...   -1.064665   \n",
            "2    Moquez mon criture. Si cela ne vous plait pa...   -1.664436   \n",
            "3    C'est pourquoi je pense qu'il est ncessaire ...    1.192783   \n",
            "4    Dautre part, jai vu que lon pouvait a...    1.255779   \n",
            "..                                                 ...         ...   \n",
            "245  Si la rponse tait,  travers l'histoire, ...   -2.064034   \n",
            "246  Je ne sais pas comment il faut procder. Le s...    0.895263   \n",
            "247  C'est de cette manire qu'ils se sont dfini...   -0.975411   \n",
            "248  Peuttre manquetil encore <url>, galement v...   -0.688790   \n",
            "249  Selon toi, fautil fusionner? Si oui, fautil, c...    0.933033   \n",
            "\n",
            "     True Label  Predicted Label  \n",
            "0             0                0  \n",
            "1             0                1  \n",
            "2             0                0  \n",
            "3             1                1  \n",
            "4             1                1  \n",
            "..          ...              ...  \n",
            "245           0                0  \n",
            "246           1                1  \n",
            "247           0                0  \n",
            "248           0                1  \n",
            "249           1                1  \n",
            "\n",
            "[250 rows x 4 columns]\n"
          ]
        }
      ],
      "source": [
        "output_df = pd.DataFrame({\n",
        "    'Sentence': test_data['sentence'],      # Original sentences\n",
        "    'True Score': test_data['score'],       # Continuous true scores\n",
        "    'True Label': true_labels_binary,       # True binary labels\n",
        "    'Predicted Label': predictions,         # Predicted binary labels\n",
        "})\n",
        "\n",
        "# Display rows\n",
        "print(output_df)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_df.to_csv('classification_output_with_scores_fr.csv', index=False)\n"
      ],
      "metadata": {
        "id": "bn9WsStiQ7Mz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "# Prepare to store predictions, probabilities, and true labels\n",
        "predictions = []\n",
        "probabilities = []\n",
        "true_labels_binary = [1 if score > 0.5 else 0 for score in true_labels]\n",
        "\n",
        "with torch.no_grad():  # Disable gradient calculation\n",
        "    for batch in test_dataloader:\n",
        "        # Convert lists of tensors to tensors\n",
        "        batch = {k: torch.stack(v) for k, v in batch.items()}\n",
        "\n",
        "        # Move input tensors to the same device as the model (if necessary)\n",
        "        for key in batch.keys():\n",
        "            batch[key] = batch[key].to(model.device)\n",
        "\n",
        "        # Get model outputs\n",
        "        # outputs = model(**batch)\n",
        "\n",
        "        # Get the predicted logits\n",
        "        logits = outputs.logits\n",
        "\n",
        "        # Apply softmax to get probabilities\n",
        "        probs = F.softmax(logits, dim=1).cpu().numpy()\n",
        "\n",
        "        # Get predicted class labels\n",
        "        predicted_label = torch.argmax(logits, dim=1).cpu().numpy()\n",
        "\n",
        "        # Store predictions and probabilities\n",
        "        predictions.extend(predicted_label)\n",
        "        probabilities.extend(probs)\n",
        "\n",
        "# Create a DataFrame with sentences, true labels, predictions, and probabilities\n",
        "output_df = pd.DataFrame({\n",
        "    'Sentence': test_data['sentence'],\n",
        "    'True Score': test_data['score'],       # Continuous true scores\n",
        "    'True Label': true_labels_binary,\n",
        "    'Predicted Label': predictions,\n",
        "    'Politeness Probability': [prob[1] for prob in probabilities],  # Probability for the \"polite\" class\n",
        "    'Impoliteness Probability': [prob[0] for prob in probabilities] # Probability for the \"impolite\" class\n",
        "})\n",
        "\n",
        "# Display rows\n",
        "print(output_df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hwbH2dTqs9Jr",
        "outputId": "505d7d7e-8c2e-480c-b12b-ad0c4c7d81ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                              Sentence  True Label  \\\n",
            "0    Allons bon, tu me dis que tu n'acceptes pas qu...           0   \n",
            "1    Bonjour Maloq  C'tait pas la peine de me fil...           0   \n",
            "2    Moquez mon criture. Si cela ne vous plait pa...           0   \n",
            "3    C'est pourquoi je pense qu'il est ncessaire ...           1   \n",
            "4    Dautre part, jai vu que lon pouvait a...           1   \n",
            "..                                                 ...         ...   \n",
            "245  Si la rponse tait,  travers l'histoire, ...           0   \n",
            "246  Je ne sais pas comment il faut procder. Le s...           1   \n",
            "247  C'est de cette manire qu'ils se sont dfini...           0   \n",
            "248  Peuttre manquetil encore <url>, galement v...           0   \n",
            "249  Selon toi, fautil fusionner? Si oui, fautil, c...           1   \n",
            "\n",
            "     Predicted Label  Politeness Probability  Impoliteness Probability  \n",
            "0                  1                0.982543                  0.017457  \n",
            "1                  1                0.982543                  0.017457  \n",
            "2                  1                0.982543                  0.017457  \n",
            "3                  1                0.982543                  0.017457  \n",
            "4                  1                0.982543                  0.017457  \n",
            "..               ...                     ...                       ...  \n",
            "245                1                0.982543                  0.017457  \n",
            "246                1                0.982543                  0.017457  \n",
            "247                1                0.982543                  0.017457  \n",
            "248                1                0.982543                  0.017457  \n",
            "249                1                0.982543                  0.017457  \n",
            "\n",
            "[250 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "output_df.to_csv('classification_output_with_scores_and_probsfrt.csv', index=False)"
      ],
      "metadata": {
        "id": "v7MN8c3NpLns"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "c106e359cc1e4a66bb6ccec7964d12bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b1e43741163e42c3944737f71af07e8e",
              "IPY_MODEL_d73b4c52587d4222b4d8813404712200",
              "IPY_MODEL_0294bc3a9d8f48628a44b9e86128e9a7"
            ],
            "layout": "IPY_MODEL_b6f563bd8e2c45d9913542f95ec33d40"
          }
        },
        "b1e43741163e42c3944737f71af07e8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_77aa134124dc4f04b0d2e4606b932322",
            "placeholder": "",
            "style": "IPY_MODEL_2149bff204494d76b209cab30fbaa3e1",
            "value": "config.json:100%"
          }
        },
        "d73b4c52587d4222b4d8813404712200": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_42586d06b43f40708abd7d95cee1ca24",
            "max": 827,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9dffa8e8a4c14b31b84ca902abb40cb5",
            "value": 827
          }
        },
        "0294bc3a9d8f48628a44b9e86128e9a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fce82f7968a14a5e94c657ba6632853d",
            "placeholder": "",
            "style": "IPY_MODEL_f3f4b85d1e744c5da1dd5ff238357a6d",
            "value": "827/827[00:00&lt;00:00,30.7kB/s]"
          }
        },
        "b6f563bd8e2c45d9913542f95ec33d40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "77aa134124dc4f04b0d2e4606b932322": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2149bff204494d76b209cab30fbaa3e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "42586d06b43f40708abd7d95cee1ca24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9dffa8e8a4c14b31b84ca902abb40cb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "fce82f7968a14a5e94c657ba6632853d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3f4b85d1e744c5da1dd5ff238357a6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f580bac555e842ae94ffd29e62709e98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e2c8459510842c491d47e4a0d8eb552",
              "IPY_MODEL_e87ed39fc2994f019a873bf6b5def6d8",
              "IPY_MODEL_d9a67ec1766444cb99a33a9648b69772"
            ],
            "layout": "IPY_MODEL_ff38210dae914397a37a86a2b4461f98"
          }
        },
        "3e2c8459510842c491d47e4a0d8eb552": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6859ae51c650492181c06b90b5c40660",
            "placeholder": "",
            "style": "IPY_MODEL_c855fdfb3d8d4a768f049b84dc631b21",
            "value": "model.safetensors:100%"
          }
        },
        "e87ed39fc2994f019a873bf6b5def6d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4741b65283f947f78334ad76ac4caf35",
            "max": 2239622872,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_79f983f21c34453585e1ef80d3b92496",
            "value": 2239622872
          }
        },
        "d9a67ec1766444cb99a33a9648b69772": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ae6d7ad932e40d79ea93503bee24dc9",
            "placeholder": "",
            "style": "IPY_MODEL_d44b67aaf7664f329505f194ee40325d",
            "value": "2.24G/2.24G[00:12&lt;00:00,269MB/s]"
          }
        },
        "ff38210dae914397a37a86a2b4461f98": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6859ae51c650492181c06b90b5c40660": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c855fdfb3d8d4a768f049b84dc631b21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4741b65283f947f78334ad76ac4caf35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79f983f21c34453585e1ef80d3b92496": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8ae6d7ad932e40d79ea93503bee24dc9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d44b67aaf7664f329505f194ee40325d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}